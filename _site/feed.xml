<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-03-20T14:58:09-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Terminal debugging</title><link href="http://localhost:4000/blog/2023/terminal-debug/" rel="alternate" type="text/html" title="Terminal debugging" /><published>2023-08-25T00:00:00-07:00</published><updated>2023-08-25T00:00:00-07:00</updated><id>http://localhost:4000/blog/2023/terminal-debug</id><content type="html" xml:base="http://localhost:4000/blog/2023/terminal-debug/"><![CDATA[<h2 id="terminal-debugging-tool-gdb">Terminal debugging tool gdb</h2>

<p>Tool <a href="https://www.sourceware.org/gdb/">gdb</a>: The GNU Project Debugger. This is the <a href="https://sourceware.org/gdb/current/onlinedocs/gdb"> user manual</a>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Start target executable app running under GDB control</span>
gdb <span class="o">[</span><span class="nt">--args</span><span class="o">]</span> &lt;target_app&gt; <span class="o">[</span>args list]

<span class="c"># attach to a running process</span>
gdb <span class="nt">-p</span> &lt;pid&gt;



<span class="c"># we can set break points</span>
<span class="nb">break</span> &lt;line_idendifier&gt;

<span class="c"># Use the run command to start your program under GDB.</span>
r

<span class="c"># we can step to the next line</span>
n
<span class="c"># or next step </span>
s
<span class="c"># or continue</span>
c

<span class="c"># print var values that show up during the step execution.</span>
p &lt;var_name&gt;

<span class="c"># quit after done</span>
quit
</code></pre></div></div>

<p>Use the pytorch segmentation fault as an example:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-c</span> <span class="s2">"import torch; print(torch)"</span>
<span class="c"># segmentation fault (core dumped)</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gdb python
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># option -c: use content/file as a core dump to examine.</span>
r <span class="nt">-c</span> <span class="s2">"import torch; print(torch)"</span>

<span class="c"># backtrace</span>
bt

<span class="c">#0  0x0000000000002360 in ?? ()</span>
<span class="c">#1  0x00007ffff7de5a6a in call_init (l=&lt;optimized out&gt;, argc=argc@entry=3, </span>
    <span class="nv">argv</span><span class="o">=</span>argv@entry<span class="o">=</span>0x7fffffffde28, <span class="nb">env</span><span class="o">=</span><span class="nb">env</span>@entry<span class="o">=</span>0xb85860<span class="o">)</span> at dl-init.c:72
<span class="c">#2  0x00007ffff7de5b7b in call_init (env=0xb85860, argv=0x7fffffffde28, </span>
    <span class="nv">argc</span><span class="o">=</span>3, <span class="nv">l</span><span class="o">=</span>&lt;optimized out&gt;<span class="o">)</span> at dl-init.c:30
<span class="c">#3  _dl_init (main_map=main_map@entry=0xeb4270, argc=3, argv=0x7fffffffde28, </span>
    <span class="nb">env</span><span class="o">=</span>0xb85860<span class="o">)</span> at dl-init.c:120
<span class="c">#4  0x00007ffff7deab86 in dl_open_worker (a=a@entry=0x7fffffffb840)</span>
    at dl-open.c:575
<span class="c">#5  0x00007ffff6d88d64 in __GI__dl_catch_error (objname=0x7fffffffb830, </span>
    <span class="nv">errstring</span><span class="o">=</span>0x7fffffffb838, <span class="nv">mallocedp</span><span class="o">=</span>0x7fffffffb82f, 
    <span class="nv">operate</span><span class="o">=</span>0x7ffff7dea7a0 &lt;dl_open_worker&gt;, <span class="nv">args</span><span class="o">=</span>0x7fffffffb840<span class="o">)</span>
    at dl-error-skeleton.c:198
<span class="c">#6  0x00007ffff7dea0d9 in _dl_open (</span>
    <span class="nv">file</span><span class="o">=</span>0x7fffdf813a60 <span class="s2">"/usr/local/lib/python3.6/dist-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so"</span>, <span class="nv">mode</span><span class="o">=</span><span class="nt">-2147483391</span>, 
    <span class="nv">caller_dlopen</span><span class="o">=</span>0x58de76 &lt;_PyImport_FindSharedFuncptr+390&gt;, <span class="nv">nsid</span><span class="o">=</span><span class="nt">-2</span>, 
    <span class="nv">argc</span><span class="o">=</span>&lt;optimized out&gt;, <span class="nv">argv</span><span class="o">=</span>&lt;optimized out&gt;, <span class="nb">env</span><span class="o">=</span>0xb85860<span class="o">)</span> at dl-open.c:660
<span class="c">#7  0x00007ffff79b2ff6 in dlopen_doit (a=a@entry=0x7fffffffba50) at dlopen.c:66</span>
<span class="c">#8  0x00007ffff6d88d64 in __GI__dl_catch_error (objname=0xb85d10, </span>
    <span class="nv">errstring</span><span class="o">=</span>0xb85d18, <span class="nv">mallocedp</span><span class="o">=</span>0xb85d08, 
    <span class="nv">operate</span><span class="o">=</span>0x7ffff79b2fa0 &lt;dlopen_doit&gt;, <span class="nv">args</span><span class="o">=</span>0x7fffffffba50<span class="o">)</span>
    at dl-error-skeleton.c:198
<span class="c">#9  0x00007ffff79b3759 in _dlerror_run (</span>
    <span class="nv">operate</span><span class="o">=</span>operate@entry<span class="o">=</span>0x7ffff79b2fa0 &lt;dlopen_doit&gt;, 
    <span class="nv">args</span><span class="o">=</span>args@entry<span class="o">=</span>0x7fffffffba50<span class="o">)</span> at dlerror.c:163
<span class="c">#10 0x00007ffff79b3092 in __dlopen (file=&lt;optimized out&gt;, mode=&lt;optimized out&gt;)</span>
    at dlopen.c:87
<span class="c">#11 0x000000000058de76 in _PyImport_FindSharedFuncptr ()</span>
<span class="c">#12 0x0000000000576b18 in _PyImport_LoadDynamicModuleWithSpec ()</span>
<span class="c">#13 0x00000000005743c5 in ?? ()</span>
<span class="c">#14 0x00000000004c47ed in PyCFunction_Call ()</span>
<span class="c">#15 0x0000000000557040 in _PyEval_EvalFrameDefault ()</span>
<span class="c">#16 0x000000000054efc1 in ?? ()</span>
<span class="c">#17 0x000000000054f24d in ?? ()</span>
<span class="c">#18 0x0000000000553aaf in _PyEval_EvalFrameDefault ()</span>
<span class="c">#19 0x000000000054e4c8 in ?? ()</span>
<span class="c">#20 0x000000000054f4f6 in ?? ()</span>
<span class="c">#21 0x0000000000553aaf in _PyEval_EvalFrameDefault ()</span>
<span class="c">#22 0x000000000054e4c8 in ?? ()</span>
<span class="c">#23 0x000000000054f4f6 in ?? ()</span>
<span class="c">#24 0x0000000000553aaf in _PyEval_EvalFrameDefault ()</span>
<span class="c">#25 0x000000000054e4c8 in ?? ()</span>
<span class="c">#26 0x000000000054f4f6 in ?? ()</span>
<span class="c">#27 0x0000000000553aaf in _PyEval_EvalFrameDefault ()</span>
<span class="c">#28 0x000000000054e4c8 in ?? ()</span>
<span class="c">#29 0x000000000054f4f6 in ?? ()</span>
<span class="c">#30 0x0000000000553aaf in _PyEval_EvalFrameDefault ()</span>
<span class="c">#31 0x000000000054e4c8 in ?? ()</span>
<span class="c">#32 0x00000000005582c2 in _PyFunction_FastCallDict ()</span>
<span class="c">#33 0x0000000000459981 in _PyObject_FastCallDict ()</span>
<span class="c">#34 0x000000000045b034 in _PyObject_CallMethodIdObjArgs ()</span>
<span class="c">#35 0x000000000057581a in PyImport_ImportModuleLevelObject ()</span>
<span class="c">#36 0x0000000000556add in _PyEval_EvalFrameDefault ()</span>
<span class="c">#37 0x000000000054efc1 in ?? ()</span>
<span class="c">#38 0x000000000054ff73 in PyEval_EvalCode ()</span>
<span class="c">#39 0x000000000054cfda in ?? ()</span>
<span class="c">#40 0x00000000004c47ed in PyCFunction_Call ()</span>
<span class="c">#41 0x0000000000557040 in _PyEval_EvalFrameDefault ()</span>
<span class="c">#42 0x000000000054efc1 in ?? ()</span>
<span class="c">#43 0x000000000054f24d in ?? ()</span>
<span class="c">#44 0x0000000000553aaf in _PyEval_EvalFrameDefault ()</span>
<span class="c">#45 0x000000000054e4c8 in ?? ()</span>
<span class="c">#46 0x000000000054f4f6 in ?? ()</span>
<span class="c">#47 0x0000000000553aaf in _PyEval_EvalFrameDefault ()</span>
<span class="c">#48 0x000000000054e4c8 in ?? ()</span>
<span class="c">#49 0x000000000054f4f6 in ?? ()</span>
<span class="c">#50 0x0000000000553aaf in _PyEval_EvalFrameDefault ()</span>
<span class="c">#51 0x000000000054e4c8 in ?? ()</span>
<span class="c">#52 0x000000000054f4f6 in ?? ()</span>
<span class="c">#53 0x0000000000553aaf in _PyEval_EvalFrameDefault ()</span>
<span class="c">#54 0x000000000054e4c8 in ?? ()</span>
<span class="c">#55 0x00000000005582c2 in _PyFunction_FastCallDict ()</span>
<span class="c">#56 0x0000000000459981 in _PyObject_FastCallDict ()</span>
<span class="c">#57 0x000000000045b034 in _PyObject_CallMethodIdObjArgs ()</span>
<span class="c">#58 0x000000000057581a in PyImport_ImportModuleLevelObject ()</span>
<span class="c">#59 0x0000000000556add in _PyEval_EvalFrameDefault ()</span>
<span class="c">#60 0x000000000054efc1 in ?? ()</span>
<span class="c">#61 0x000000000054ff73 in PyEval_EvalCode ()</span>
<span class="c">#62 0x000000000042c37a in PyRun_SimpleStringFlags ()</span>
<span class="c">#63 0x0000000000441178 in Py_Main ()</span>
<span class="c">#64 0x0000000000421f64 in main ()</span>
</code></pre></div></div>

<h2 id="file-content-investigation">File content investigation</h2>

<h3 id="investigate-dynamic-lib-files">Investigate dynamic lib files</h3>

<p>Tool <a href="https://linux.die.net/man/1/ldd">ldd</a>: print shared library dependencies.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ldd /usr/local/lib/python3.6/dist-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so

<span class="c"># linux-vdso.so.1 =&gt;  (0x00007ffcce1f5000)</span>
<span class="c">#   libshm.so =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libshm.so (0x00007f37cdcac000)</span>
<span class="c">#   libcudart.so.9.0 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libcudart.so.9.0 (0x00007f37cda3d000)</span>
<span class="c">#   libnvToolsExt.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libnvToolsExt.so.1 (0x00007f37cd833000)</span>
<span class="c">#   libcudnn.so.7 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libcudnn.so.7 (0x00007f37bc5c0000)</span>
<span class="c">#   libTH.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libTH.so.1 (0x00007f37b9a91000)</span>
<span class="c">#   libTHS.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libTHS.so.1 (0x00007f37b9860000)</span>
<span class="c">#   libTHNN.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libTHNN.so.1 (0x00007f37b951d000)</span>
<span class="c">#   libATen.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libATen.so.1 (0x00007f37b8d0f000)</span>
<span class="c">#   libTHC.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libTHC.so.1 (0x00007f37a4353000)</span>
<span class="c">#   libTHCS.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libTHCS.so.1 (0x00007f37a3fc3000)</span>
<span class="c">#   libTHCUNN.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libTHCUNN.so.1 (0x00007f379e8ef000)</span>
<span class="c">#   libnccl.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libnccl.so.1 (0x00007f379be65000)</span>
<span class="c">#   libgcc_s.so.1 =&gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f379bc4e000)</span>
<span class="c">#   libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f379ba2f000)</span>
<span class="c">#   libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f379b64f000)</span>
<span class="c">#   /lib64/ld-linux-x86-64.so.2 (0x00007f37cf854000)</span>
<span class="c">#   librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007f379b447000)</span>
<span class="c">#   libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f379b0f1000)</span>
<span class="c">#   libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f379aeed000)</span>
<span class="c">#   libstdc++.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f379ab65000)</span>
<span class="c">#   libgomp.so.1 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libgomp.so.1 (0x00007f379a94e000)</span>
<span class="c">#   libcublas.so.9.0 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libcublas.so.9.0 (0x00007f3797515000)</span>
<span class="c">#   libcurand.so.9.0 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libcurand.so.9.0 (0x00007f37935b0000)</span>
<span class="c">#   libcusparse.so.9.0 =&gt; /usr/local/lib/python3.6/dist-packages/torch/lib/libcusparse.so.9.0 (0x00007f378fe45000)</span>
</code></pre></div></div>

<h3 id="list-all-symbols-defined-in-the-lib-file">List all symbols defined in the lib file</h3>

<p>Reference: <a href="https://stackoverflow.com/questions/34732/how-do-i-list-the-symbols-in-a-so-file">How do I list the symbols in a .so file</a></p>

<p>Using GNU <code class="language-plaintext highlighter-rouge">nm</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nm <span class="nt">-gD</span> yourLib.so

<span class="c"># Add the "-C" option to see symbols of a C++ library</span>
nm <span class="nt">-gDC</span> yourLib.so
</code></pre></div></div>

<p>If your .so file is in elf format, you have two options:</p>

<p>Either <code class="language-plaintext highlighter-rouge">objdump</code> (<code class="language-plaintext highlighter-rouge">-C</code> is also useful for demangling C++):</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>objdump <span class="nt">-TC</span> libz.so

libz.so:     file format elf64-x86-64

DYNAMIC SYMBOL TABLE:
0000000000002010 l    d  .init  0000000000000000              .init
0000000000000000      DF <span class="k">*</span>UND<span class="k">*</span>  0000000000000000  GLIBC_2.2.5 free
0000000000000000      DF <span class="k">*</span>UND<span class="k">*</span>  0000000000000000  GLIBC_2.2.5 __errno_location
0000000000000000  w   D  <span class="k">*</span>UND<span class="k">*</span>  0000000000000000              _ITM_deregisterTMCloneTable
</code></pre></div></div>
<p>or use <code class="language-plaintext highlighter-rouge">readelf</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>readelf <span class="nt">-Ws</span> libz.so
Symbol table <span class="s1">'.dynsym'</span> contains 112 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 0000000000002010     0 SECTION LOCAL  DEFAULT   10
     2: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND free@GLIBC_2.2.5 <span class="o">(</span>14<span class="o">)</span>
     3: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __errno_location@GLIBC_2.2.5 <span class="o">(</span>14<span class="o">)</span>
     4: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_deregisterTMCloneTable
</code></pre></div></div>
<h2 id="reference">Reference</h2>

<p><a href="https://github.com/pytorch/pytorch/issues/4101">Segmentation Fault when importing Torch</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[practice]]></summary></entry><entry><title type="html">Pytorch coding</title><link href="http://localhost:4000/blog/2023/pytorch-coding/" rel="alternate" type="text/html" title="Pytorch coding" /><published>2023-08-09T09:50:00-07:00</published><updated>2023-08-09T09:50:00-07:00</updated><id>http://localhost:4000/blog/2023/pytorch-coding</id><content type="html" xml:base="http://localhost:4000/blog/2023/pytorch-coding/"><![CDATA[<h2 id="checkpoints-saving-and-loading">Checkpoints saving and loading</h2>

<p><a href="https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html">Saving and loading a general checkpoint in pytorch</a></p>

<h3 id="define-initialize-and-train-a-model">Define, initialize and train a model:</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">pool</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">pool</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">net</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>


<span class="c1"># optimizer
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Train
# ...
</span>
</code></pre></div></div>

<h3 id="save-checkpoint">Save checkpoint</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Additional information
</span><span class="n">EPOCH</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">PATH</span> <span class="o">=</span> <span class="s">"model.pt"</span>
<span class="n">LOSS</span> <span class="o">=</span> <span class="mf">0.4</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">({</span>
            <span class="s">'epoch'</span><span class="p">:</span> <span class="n">EPOCH</span><span class="p">,</span>
            <span class="s">'model_state_dict'</span><span class="p">:</span> <span class="n">net</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>
            <span class="s">'optimizer_state_dict'</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>
            <span class="s">'loss'</span><span class="p">:</span> <span class="n">LOSS</span><span class="p">,</span>
            <span class="p">},</span> <span class="n">PATH</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="load-checkpoint">Load checkpoint</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load the checkpoint
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s">'model_state_dict'</span><span class="p">])</span>
<span class="n">optimizer</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s">'optimizer_state_dict'</span><span class="p">])</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s">'epoch'</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s">'loss'</span><span class="p">]</span>

<span class="c1"># continue to evaluation or training
</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
<span class="c1"># - or -
</span><span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="torchscript-tracing-tutorial">TorchScript tracing tutorial</h2>
<p>Here is an <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">introduction tutorial</a> on TorchScript and the documentation (<a href="https://pytorch.org/tutorials/advanced/cpp_export.html">LOADING A TORCHSCRIPT MODEL IN C++</a>) about it.</p>

<h3 id="converting-to-torch-script-via-tracing">Converting to Torch Script via Tracing</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torchvision</span>

<span class="c1"># An instance of your model.
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">resnet18</span><span class="p">()</span>

<span class="c1"># An example input you would normally provide to your model's forward() method.
</span><span class="n">example</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>

<span class="c1"># Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.
</span><span class="n">traced_script_module</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">example</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="converting-to-torch-script-via-annotation">Converting to Torch Script via Annotation</h3>
<p>In case your model employs particular forms of control flow (data dependent if-else).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">input</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
          <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="nf">mv</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">+</span> <span class="nb">input</span>
        <span class="k">return</span> <span class="n">output</span>

<span class="n">my_module</span> <span class="o">=</span> <span class="nc">MyModule</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
<span class="n">sm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">script</span><span class="p">(</span><span class="n">my_module</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="serializing-your-script-module-to-a-file">Serializing Your Script Module to a File</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">traced_script_module</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="s">"traced_resnet_model.pt"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="loading-loading-your-script-module-in-c">Loading Loading Your Script Module in C++</h3>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;torch/script.h&gt;</span><span class="c1"> // One-stop header.</span><span class="cp">
</span>
<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;memory&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">"usage: example-app &lt;path-to-exported-script-module&gt;</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>


  <span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">script</span><span class="o">::</span><span class="n">Module</span> <span class="n">module</span><span class="p">;</span>
  <span class="k">try</span> <span class="p">{</span>
    <span class="c1">// Deserialize the ScriptModule from a file using torch::jit::load().</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
  <span class="p">}</span>
  <span class="k">catch</span> <span class="p">(</span><span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">Error</span><span class="o">&amp;</span> <span class="n">e</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">"error loading the model</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"ok</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Depending on LibTorch and Building the Application:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cmake_minimum_required<span class="o">(</span>VERSION 3.0 FATAL_ERROR<span class="o">)</span>
project<span class="o">(</span>custom_ops<span class="o">)</span>

find_package<span class="o">(</span>Torch REQUIRED<span class="o">)</span>

add_executable<span class="o">(</span>example-app example-app.cpp<span class="o">)</span>
target_link_libraries<span class="o">(</span>example-app <span class="s2">"</span><span class="k">${</span><span class="nv">TORCH_LIBRARIES</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
set_property<span class="o">(</span>TARGET example-app PROPERTY CXX_STANDARD 14<span class="o">)</span>
</code></pre></div></div>

<h2 id="pytorch-extensions">Pytorch Extensions</h2>

<p><a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">CUSTOM C++ AND CUDA EXTENSIONS</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[practice]]></summary></entry><entry><title type="html">Cuda coding</title><link href="http://localhost:4000/blog/2023/cuda-coding/" rel="alternate" type="text/html" title="Cuda coding" /><published>2023-08-03T12:30:00-07:00</published><updated>2023-08-03T12:30:00-07:00</updated><id>http://localhost:4000/blog/2023/cuda-coding</id><content type="html" xml:base="http://localhost:4000/blog/2023/cuda-coding/"><![CDATA[<h4 id="cuda-multithreading">Cuda multithreading</h4>

<p><a href="https://developer.nvidia.com/blog/cuda-pro-tip-always-set-current-device-avoid-multithreading-bugs/">CUDA Pro Tip: Always Set the Current Device to Avoid Multithreading Bugs</a></p>

<p>How to select which GPU to execute CUDA calls on? The CUDA runtime API is <b>state-based</b>, and threads should execute <code class="language-plaintext highlighter-rouge">cudaSetDevice()</code> to set the current GPU.</p>

<p>The CUDA runtime API is thread-safe, which means it maintains <b>per-thread state</b> about the current device. This is very important as it allows threads to concurrently submit work to different devices. If current device is not set for the thread, either it will use the default device (device 0) or if it is a reused thread it will reuse its last device setting.</p>

<p>Pro Tip: always call <code class="language-plaintext highlighter-rouge">cudaSetDevice()</code> first when you spawn a new host thread.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cudaSetDevice</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">a</span><span class="p">,</span><span class="n">bytes</span><span class="p">);</span>

<span class="cp">#pragma omp parallel
</span><span class="p">{</span>
  <span class="c1">// multiple threads calling the kernel</span>
  <span class="n">cudaSetDevice</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
  <span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="n">threads</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<h4 id="concurrency-with-streams">Concurrency with streams</h4>

<p><a href="https://developer.nvidia.com/blog/gpu-pro-tip-cuda-7-streams-simplify-concurrency/">GPU Pro Tip: CUDA 7 Streams Simplify Concurrency</a></p>

<p>CUDA Applications manage concurrency by executing asynchronous commands in streams, sequences of commands that execute in order. 
[See the post <a href="https://developer.nvidia.com/blog/parallelforall/how-overlap-data-transfers-cuda-cc/">How to Overlap Data Transfers in CUDA C/C++</a> for an example.]</p>

<p>When you execute asynchronous CUDA commands without specifying a stream, the runtime uses the default stream.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span> <span class="n">blocks</span><span class="p">,</span> <span class="n">threads</span><span class="p">,</span> <span class="n">bytes</span> <span class="o">&gt;&gt;&gt;</span><span class="p">();</span>    <span class="c1">// stream 0 (default)</span>
  <span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span> <span class="n">blocks</span><span class="p">,</span> <span class="n">threads</span><span class="p">,</span> <span class="n">bytes</span><span class="p">,</span> <span class="mi">0</span> <span class="o">&gt;&gt;&gt;</span><span class="p">();</span> <span class="c1">// stream 0</span>
</code></pre></div></div>

<p>Before CUDA 7, the default stream is a single <b>per-device</b> default stream which implicitly synchronizes with all other streams on the device.</p>

<p>CUDA 7 introduces an independent <b>per-thread</b> default stream for every host thread, which avoids the serialization of the legacy default stream. These default streams are regular streams. The commands issued to the default streams by different host threads can run concurrently.</p>

<p>To enable per-thread default streams in CUDA 7 and later, you can either compile with the <code class="language-plaintext highlighter-rouge">nvcc</code> command-line option <code class="language-plaintext highlighter-rouge">--default-stream per-thread</code>, or <code class="language-plaintext highlighter-rouge">#define CUDA_API_PER_THREAD_DEFAULT_STREAM</code> preprocessor macro before including CUDA headers (<code class="language-plaintext highlighter-rouge">cuda.h</code> or <code class="language-plaintext highlighter-rouge">cuda_runtime.h</code>).</p>

<h5 id="asynchronous-commands-in-cuda">Asynchronous Commands in CUDA</h5>
<p>As described by the CUDA C Programming Guide, asynchronous commands return control to the calling host thread before the device has finished the requested task (they are non-blocking). These commands are:</p>

<ul>
    <li>Kernel launches;</li>
    <li>Memory copies between two addresses to the same device memory;</li>
    <li>Memory copies from host to device of a memory block of 64 KB or less;</li>
    <li>Memory copies performed by functions with the Async suffix;</li>
    <li>Memory set function calls.</li>
</ul>

<h5 id="a-multi-threading-example">A Multi-threading Example</h5>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;pthread.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span>
<span class="k">const</span> <span class="kt">int</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">20</span><span class="p">;</span>

<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">kernel</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">tid</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">pow</span><span class="p">(</span><span class="mf">3.14159</span><span class="p">,</span><span class="n">i</span><span class="p">));</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="o">*</span><span class="nf">launch_kernel</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">dummy</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// Bound thread to device for each thread.</span>
    <span class="n">cudaSetDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>

    <span class="kt">float</span> <span class="o">*</span><span class="n">data</span><span class="p">;</span>
    <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="p">,</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

    <span class="c1">// Use default stream: per-device or per thread default?</span>
    <span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>

    <span class="c1">// Sync stream 0 within each thread after kernel run.</span>
    <span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>

    <span class="k">return</span> <span class="nb">NULL</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="kt">int</span> <span class="n">num_threads</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>

    <span class="n">pthread_t</span> <span class="n">threads</span><span class="p">[</span><span class="n">num_threads</span><span class="p">];</span>

    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_threads</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">threads</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">launch_kernel</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Error creating threadn"</span><span class="p">);</span>
            <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_threads</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span><span class="p">(</span><span class="n">pthread_join</span><span class="p">(</span><span class="n">threads</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Error joining threadn"</span><span class="p">);</span>
            <span class="k">return</span> <span class="mi">2</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="n">cudaDeviceReset</span><span class="p">();</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>(a) Compile with the legacy default stream will behavior:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc ./pthread_test.cu <span class="nt">-o</span> pthreads_legacy
</code></pre></div></div>
<p>When we run this in <code class="language-plaintext highlighter-rouge">nvvp</code>, we see a single stream, the default stream, with all kernel launches serialized.</p>

<p>(b) Compile it with the new per-thread default stream option:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc <span class="nt">--default-stream</span> per-thread ./pthread_test.cu <span class="nt">-o</span> pthreads_per_thread
</code></pre></div></div>
<p>Each thread creates a new stream automatically and they do not synchronize, so the kernels from all eight threads run concurrently.</p>]]></content><author><name></name></author><category term="note-posts" /><category term="notes" /><category term="code" /><summary type="html"><![CDATA[Cuda multithreading]]></summary></entry><entry><title type="html">CVCuda installation</title><link href="http://localhost:4000/blog/2023/cvcuda-installation/" rel="alternate" type="text/html" title="CVCuda installation" /><published>2023-08-01T13:00:00-07:00</published><updated>2023-08-01T13:00:00-07:00</updated><id>http://localhost:4000/blog/2023/cvcuda-installation</id><content type="html" xml:base="http://localhost:4000/blog/2023/cvcuda-installation/"><![CDATA[<h4 id="cvcuda-installation-references">CVCUDA Installation references</h4>

<p><a href="https://cvcuda.github.io">cvcuda documentation</a></p>

<p><a href="https://github.com/CVCUDA/CV-CUDA">cvcuda github repo</a></p>

<h4 id="run-samples-in-docker">Run samples in docker</h4>

<p><b>1</b>. Download and install cvcuda samples from <a href="https://github.com/CVCUDA/CV-CUDA/releases/tag/v0.3.1-beta">CVCUDA release</a>. The release files are all based on cuda 12.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># download</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> ~/tmp
<span class="nb">cd</span> ~/tmp
curl <span class="nt">-L</span> https://github.com/CVCUDA/CV-CUDA/releases/download/v0.3.1-beta/cvcuda-samples-0.3.1_beta-cuda12-x86_64-linux.deb <span class="nt">-o</span> cvcuda-samples-0.3.1_beta-cuda12-x86_64-linux.deb
<span class="c"># install</span>
dpkg <span class="nt">-i</span> cvcuda-samples-0.3.1_beta-cuda12-x86_64-linux.deb</code></pre></figure>

<p><b>2</b>. Run the docker, this image comes with python 3.8:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># link the sample folder</span>
docker run <span class="nt">-it</span> <span class="nt">--gpus</span><span class="o">=</span>all <span class="nt">-v</span>  /opt/nvidia/cvcuda0/samples:/samples nvcr.io/nvidia/tensorrt:23.04-py3</code></pre></figure>

<p>Tip: Find the desired base docker image with TenserRT and cuda 12 from <a href="https://docs.nvidia.com/deeplearning/tensorrt/container-release-notes/index.html">tensorrt container release notes page</a>.</p>

<p><b>3</b>. Ensure the scripts are executable: 
(From step 3 to 6, the cmd are run in the docker container.)</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># copy the samples into the user folder.</span>
<span class="nb">cp</span> <span class="nt">-rf</span> /opt/nvidia/cvcuda<span class="k">*</span>/samples ~/
<span class="nb">cd</span> ~/samples
<span class="nb">chmod </span>a+x scripts/<span class="k">*</span>.sh
<span class="nb">chmod </span>a+x scripts/<span class="k">*</span>.py</code></pre></figure>

<p><b>4</b>. Install sample dependencies:</p>

<p>Basically, step by step run the script in <code class="language-plaintext highlighter-rouge">./scripts/install_dependencies.sh</code> with the following modification:</p>

<p>a) pip3 package versions</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Install torch and torchvision for cuda12:</span>
pip3 <span class="nb">install</span> <span class="nt">--pre</span> torch torchvision torchaudio <span class="nt">--index-url</span> https://download.pytorch.org/whl/nightly/cu121
<span class="c"># Install pycuda with auto version (latest version installed: 2022.2.2):</span>
pip3 <span class="nb">install </span><span class="nv">av</span><span class="o">==</span>10.0.0 pycuda <span class="nv">nvtx</span><span class="o">==</span>0.2.5
<span class="c"># Install onnx</span>
pip3 <span class="nb">install </span>onnx</code></pre></figure>

<p>In script, we can do the following (replacing line 55):</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'55s+.*+pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121\npip3 install av==10.0.0 pycuda nvtx==0.2.5\npip3 install onnx\n+'</span> scripts/install_dependencies.sh</code></pre></figure>

<p>b) Refine exporting PATH: replace echo “export PATH=$PATH:<some_path>" with "export PATH=\${PATH}:<some_path>"</some_path></some_path></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s+$PATH+\\${PATH}+'</span> scripts/install_dependencies.sh</code></pre></figure>

<p>c) Edit <code class="language-plaintext highlighter-rouge">setup.py</code> for <code class="language-plaintext highlighter-rouge">torchnvjpeg</code> to specify <code class="language-plaintext highlighter-rouge">std:c++17</code> as the compiler to be compatible with <code class="language-plaintext highlighter-rouge">pytorch</code>.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/std=c++14/std=c++17/'</span> torchnvjpeg/setup.py</code></pre></figure>

<p><b>5</b>. Install the CV-CUDA packages in the docker.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># download</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /tmp
<span class="nb">cd</span> /tmp
curl <span class="nt">-L</span> https://github.com/CVCUDA/CV-CUDA/releases/download/v0.3.1-beta/nvcv-dev-0.3.1_beta-cuda12-x86_64-linux.deb <span class="nt">-o</span> nvcv-dev-0.3.1_beta-cuda12-x86_64-linux.deb

curl <span class="nt">-L</span> https://github.com/CVCUDA/CV-CUDA/releases/download/v0.3.1-beta/nvcv-lib-0.3.1_beta-cuda12-x86_64-linux.deb <span class="nt">-o</span> nvcv-lib-0.3.1_beta-cuda12-x86_64-linux.deb

curl <span class="nt">-L</span> https://github.com/CVCUDA/CV-CUDA/releases/download/v0.3.1-beta/nvcv-python3.8-0.3.1_beta-cuda12-x86_64-linux.deb <span class="nt">-o</span> nvcv-python3.8-0.3.1_beta-cuda12-x86_64-linux.deb

<span class="c"># install</span>
dpkg <span class="nt">-i</span> nvcv-lib-0.3.1_beta-cuda12-x86_64-linux.deb
dpkg <span class="nt">-i</span> nvcv-dev-0.3.1_beta-cuda12-x86_64-linux.deb
dpkg <span class="nt">-i</span> nvcv-python3.8-0.3.1_beta-cuda12-x86_64-linux.deb</code></pre></figure>

<p><b>6</b>. Build and run the samples:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd</span> ~/samples 
./scripts/build_samples.sh
./scripts/run_samples.sh</code></pre></figure>

<p><b>7</b>. Check the sample run results in the local terminal outside the docker:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Check the running docker containers and get the container id of the sample run:</span>
docker ps
<span class="c"># copy the output file to local machine (example below):</span>
docker <span class="nb">cp</span> &lt;container_id&gt;:/tmp/out_Weimaraner.jpg ~/out_Weimaraner.jpg</code></pre></figure>

<h4 id="run-segmentation-triton-sample">Run segmentation triton sample</h4>

<p>Triton server docker run the <a href="https://github.com/CVCUDA/CV-CUDA/tree/release_v0.3.x/samples/segmentation_triton">segmentation on triton example</a> with corrections.</p>

<h5 id="set-up-triton-server">Set up triton server</h5>

<p><b>1</b>. Find the right tritonserver release docker image that matches our devbox setup (<a href="https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/index.html">release note</a>, <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver/tags">tags</a>)</p>

<p>I’ll go with <a href="https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel-23-02.html">image 23.02-py3</a>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Install the libs first as in the last section.
</code></pre></div></div>

<p><b>2</b>. Start the triton server docker with the cvcuda mounted:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">docker run <span class="nt">--shm-size</span><span class="o">=</span>1g <span class="nt">--ulimit</span> <span class="nv">memlock</span><span class="o">=</span><span class="nt">-1</span> <span class="nt">-p</span> 8000:8000 <span class="nt">-p</span> 8001:8001 <span class="nt">-p</span> 8002:8002 <span class="nt">--ulimit</span> <span class="nv">stack</span><span class="o">=</span>67108864 <span class="nt">-ti</span> <span class="nt">--gpus</span><span class="o">=</span>all <span class="nt">-v</span> /opt/nvidia/cvcuda0:/cvcuda <span class="nt">-w</span> /cvcuda nvcr.io/nvidia/tritonserver:23.02-py3</code></pre></figure>

<p><b>3</b>. Install dependencies on the triton server docker:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd</span> /cvcuda/samples/scripts
<span class="nb">touch </span>my_install_dependencies.sh
vim my_install_dependencies.sh

<span class="c"># copy the following code into the my_install_dependencies.sh</span></code></pre></figure>

<p>The code to be copied:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">mkdir</span> <span class="nt">-p</span> ~/samples
<span class="nb">cd</span> /cvcuda
<span class="nb">cp</span> <span class="nt">-r</span> samples/. ~/samples

<span class="nb">cd</span> ~/samples
<span class="nb">chmod </span>a+x scripts/<span class="k">*</span>.sh
<span class="nb">chmod </span>a+x scripts/<span class="k">*</span>.py

<span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'55s+.*+pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121\npip3 install av==10.0.0 pycuda nvtx==0.2.5\npip3 install onnx\n+'</span> scripts/install_dependencies.sh

<span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s+$PATH+\\${PATH}+'</span> scripts/install_dependencies.sh

<span class="c"># add new line after torchnvjpeg repo is downloaded</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">grep</span> <span class="nt">-n</span> <span class="s1">'scripts/install_dependencies.sh'</span> <span class="nt">-e</span> <span class="s1">'cd torchnvjpeg'</span> | <span class="nb">head</span> <span class="nt">-1</span> | <span class="nb">cut</span> <span class="nt">-f1</span> <span class="nt">-d</span>:<span class="si">)</span><span class="s2">ised -i -e 's/std=c++14/std=c++17/' torchnvjpeg/setup.py"</span> scripts/install_dependencies.sh

<span class="c"># install dependencies. (Q: How to skip user ENTER while running the script?)</span>
./scripts/install_dependencies.sh</code></pre></figure>

<p>Install dependencies:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">bash my_install_dependencies.sh</code></pre></figure>

<p><b>4</b>. Install cmake that meets the version requirement into <code class="language-plaintext highlighter-rouge">/usr/local/bin</code> which comes before <code class="language-plaintext highlighter-rouge">/usr/bin</code> in system <code class="language-plaintext highlighter-rouge">PATH</code> where the existing cmake is.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">cmake <span class="nt">--version</span>
which cmake

<span class="nb">cd</span> /opt
curl <span class="nt">-L</span> https://github.com/Kitware/CMake/releases/download/v3.26.5/cmake-3.26.5-linux-x86_64.sh <span class="nt">--output</span> cmake-3.26.5-linux-x86_64.sh
<span class="nb">chmod </span>a+x cmake-3.26.5-linux-x86_64.sh
bash /opt/cmake-3.26.5-linux-x86_64.sh

<span class="nb">ln</span> <span class="nt">-s</span> /opt/cmake-3.26.5-linux-x86_64/bin/<span class="k">*</span> /usr/local/bin

<span class="c"># export CMAKE_ROOT=/opt/cmake-3.26.5-linux-x86_64/share/cmake-3.26</span>
<span class="c"># Remember to refresh after new cmake is installed</span>
<span class="nb">hash</span> <span class="nt">-r</span>

cmake <span class="nt">--version</span> </code></pre></figure>

<p><b>5</b>. Build the samples</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd</span> ~/samples
<span class="nb">cp</span> ./scripts/build_samples.sh ./scripts/my_build_samples.sh
<span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s+cmake ..+cmake .. -DCMAKE_PREFIX_PATH=/cvcuda/lib/x86_64-linux-gnu/cmake+'</span> scripts/my_build_samples.sh
./scripts/my_build_samples.sh</code></pre></figure>

<p><b>6</b>. Start the triton server:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Add the lib path to the libcvcuda.so.0</span>
<span class="nb">export </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/cvcuda/lib/x86_64-linux-gnu/

<span class="c"># To resolve "ModuleNotFoundError: No module named 'cvcuda'"</span>
<span class="c"># option 1: go to the folder where the cvcuda.cpython-38-x86_64-linux-gnu.so is installed</span>
<span class="nb">cd</span> /cvcuda/lib/x86_64-linux-gnu/python

<span class="c"># option 2: create symlink in one of the default sys.path</span>
<span class="nb">ln</span> <span class="nt">-s</span> /cvcuda/lib/x86_64-linux-gnu/python/<span class="k">*</span> /usr/lib/python3/dist-packages

<span class="c"># Start the triton server</span>
tritonserver <span class="nt">--model-repository</span> ~/samples/segmentation_triton/python/models </code></pre></figure>

<h5 id="set-up-triton-client">Set up triton client</h5>
<p><b>1</b>. Start docker to run triton client:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">docker run <span class="nt">-ti</span> <span class="nt">--net</span> host <span class="nt">--gpus</span><span class="o">=</span>all <span class="nt">-v</span> /opt/nvidia/cvcuda0:/cvcuda nvcr.io/nvidia/tritonserver:23.02-py3-sdk <span class="nt">-w</span> /cvcuda /bin/bash</code></pre></figure>

<p><b>2</b>. Install dependencies into the client docker run:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd</span> /cvcuda/samples/scripts
bash my_install_dependencies.sh</code></pre></figure>

<p><b>3</b>. Run the segmentation on folder containing images:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">export </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/cvcuda/lib/x86_64-linux-gnu/

<span class="c"># option 1. hack python sys.path to include the lib folder</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s+import cvcuda+sys.path.append('/cvcuda/lib/x86_64-linux-gnu/python')</span><span class="se">\n</span><span class="s2">import cvcuda+"</span> ~/samples/segmentation_triton/python/triton_client.py

<span class="c"># option 2. create symlink (Q: How default sys.path is set?)</span>
<span class="nb">ln</span> <span class="nt">-s</span> /cvcuda/lib/x86_64-linux-gnu/python/<span class="k">*</span> /usr/lib/python3/dist-packages

python3 ~/samples/segmentation_triton/python/triton_client.py <span class="nt">-i</span> ~/samples/assets/images <span class="nt">-b</span> 2

<span class="c"># check the results</span>
<span class="nb">ls</span> /tmp</code></pre></figure>]]></content><author><name></name></author><category term="note-posts" /><category term="notes" /><summary type="html"><![CDATA[tutorial]]></summary></entry><entry><title type="html">Conda Tutorial</title><link href="http://localhost:4000/blog/2023/conda-tutorial/" rel="alternate" type="text/html" title="Conda Tutorial" /><published>2023-07-31T05:00:00-07:00</published><updated>2023-07-31T05:00:00-07:00</updated><id>http://localhost:4000/blog/2023/conda-tutorial</id><content type="html" xml:base="http://localhost:4000/blog/2023/conda-tutorial/"><![CDATA[<h4 id="python-version-management-tool--conda">Python version management tool – conda</h4>

<h5 id="adding-a-python-package">Adding a python package</h5>
<p>The default installation path should be <code class="language-plaintext highlighter-rouge">site-packages</code> of <code class="language-plaintext highlighter-rouge">python</code> folder. However, if you’d like to add a python package with customized installation path to the conda env: use command <a href="https://docs.conda.io/projects/conda-build/en/latest/resources/commands/conda-develop.html">conda-develop</a>.</p>

<h5 id="adding-shared-libraries">Adding shared libraries</h5>
<p>Check <a href="https://docs.conda.io/projects/conda-build/en/latest/resources/use-shared-libraries.html">here</a> for conda shared libraries.</p>

<p>Conda depends primarily on searching directories for matching filenames. It does not currently use side-by-side assemblies.</p>

<p>For now, most DLLs are installed into <code class="language-plaintext highlighter-rouge">(install prefix)\\Library\\bin</code> –Q:what is this path?. This path is added to <code class="language-plaintext highlighter-rouge">os.environ["PATH"]</code> for all Python processes, so that DLLs can be located, regardless of the value of the system’s PATH environment variable.</p>

<p>Check the list of the installed packages:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda list

<span class="c"># or show only pip packages</span>
pip list
</code></pre></div></div>

<h5 id="execution-environment-var-setting-in-conda-env">Execution environment var setting in conda env</h5>

<p>Reference <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#macos-and-linux">here</a>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> <span class="nv">$CONDA_PREFIX</span>

<span class="c"># edit the var </span>
vim etc/conda/activate.d/env_vars.sh
<span class="c"># example content: export MY_KEY='secret-key-value'</span>
vim etc/conda/deactivate.d/env_vars.sh
<span class="c"># example content: unset MY_KEY</span>

<span class="c"># Check by the following</span>
conda activate analytics
</code></pre></div></div>

<p>Another option to <a href="https://datacomy.com/python/anaconda/add_folder_to_path/">add a Python packages folder to conda path</a>:
(Not verified yet)</p>

<p>To permanently include packages or folder into the <code class="language-plaintext highlighter-rouge">PYTHONPATH</code> of an conda environment, use <a href="https://docs.conda.io/projects/conda-build/en/latest/resources/commands/conda-develop.html">conda develop</a>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda activate &lt;your-env&gt;

conda develop /PATH/TO/YOUR/FOLDER/OF/MODULES
</code></pre></div></div>

<p>This command will create file named <code class="language-plaintext highlighter-rouge">conda.pth</code> file in the site-packages folder of your environment, e.g. <code class="language-plaintext highlighter-rouge">~/YOUR_ENV/lib/pythonX.X/site-packages</code>.</p>

<p>As an alternative, you can just add a <code class="language-plaintext highlighter-rouge">conda.pth</code> file in <code class="language-plaintext highlighter-rouge">~/YOUR_ENV/lib/pythonX.X/site-packages</code> with the folder that you want to include in your <code class="language-plaintext highlighter-rouge">PYTHONPATH</code>. The filename can be different as long as it has the <code class="language-plaintext highlighter-rouge">.pth</code> extension. Every line of the file can contain a folder.</p>

<p><a href="https://conda.io/projects/conda/en/latest/user-guide/configuration/use-condarc.html">Using the .condarc conda configuration file</a></p>

<p>The <code class="language-plaintext highlighter-rouge">.condarc</code> file can change many parameters, including:</p>
<ul>
    <li>Where conda looks for packages.</li>
    <li>If and how conda uses a proxy server.</li>
    <li>Where conda lists known environments.</li>
    <li>Whether to update the Bash prompt with the currently activated environment name.</li>
    <li>Whether user-built packages should be uploaded to Anaconda.org.</li>
    <li>What default packages or features to include in new environments.</li>
</ul>

<p>Creating and editing the <code class="language-plaintext highlighter-rouge">.condarc</code> with <code class="language-plaintext highlighter-rouge">conda config</code> <a href="https://conda.io/projects/conda/en/latest/commands/config.html">commads</a>. Example:</p>
<pre><code class="language-base">conda config --add channels conda-forge
conda config --set auto_update_conda False
</code></pre>

<p>Conda looks in the following locations for a <code class="language-plaintext highlighter-rouge">.condarc</code> file:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">on_win</span><span class="p">:</span>
    <span class="n">SEARCH_PATH</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s">"C:/ProgramData/conda/.condarc"</span><span class="p">,</span>
        <span class="s">"C:/ProgramData/conda/condarc"</span><span class="p">,</span>
        <span class="s">"C:/ProgramData/conda/condarc.d"</span><span class="p">,</span>
    <span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">SEARCH_PATH</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s">"/etc/conda/.condarc"</span><span class="p">,</span>
        <span class="s">"/etc/conda/condarc"</span><span class="p">,</span>
        <span class="s">"/etc/conda/condarc.d/"</span><span class="p">,</span>
        <span class="s">"/var/lib/conda/.condarc"</span><span class="p">,</span>
        <span class="s">"/var/lib/conda/condarc"</span><span class="p">,</span>
        <span class="s">"/var/lib/conda/condarc.d/"</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">SEARCH_PATH</span> <span class="o">+=</span> <span class="p">(</span>
    <span class="s">"$CONDA_ROOT/.condarc"</span><span class="p">,</span>
    <span class="s">"$CONDA_ROOT/condarc"</span><span class="p">,</span>
    <span class="s">"$CONDA_ROOT/condarc.d/"</span><span class="p">,</span>
    <span class="s">"$XDG_CONFIG_HOME/conda/.condarc"</span><span class="p">,</span>
    <span class="s">"$XDG_CONFIG_HOME/conda/condarc"</span><span class="p">,</span>
    <span class="s">"$XDG_CONFIG_HOME/conda/condarc.d/"</span><span class="p">,</span>
    <span class="s">"~/.config/conda/.condarc"</span><span class="p">,</span>
    <span class="s">"~/.config/conda/condarc"</span><span class="p">,</span>
    <span class="s">"~/.config/conda/condarc.d/"</span><span class="p">,</span>
    <span class="s">"~/.conda/.condarc"</span><span class="p">,</span>
    <span class="s">"~/.conda/condarc"</span><span class="p">,</span>
    <span class="s">"~/.conda/condarc.d/"</span><span class="p">,</span>
    <span class="s">"~/.condarc"</span><span class="p">,</span>
    <span class="s">"$CONDA_PREFIX/.condarc"</span><span class="p">,</span>
    <span class="s">"$CONDA_PREFIX/condarc"</span><span class="p">,</span>
    <span class="s">"$CONDA_PREFIX/condarc.d/"</span><span class="p">,</span>
    <span class="s">"$CONDARC"</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<h5 id="conda-env-creation-using-a-yml-file">Conda env creation using a yml file</h5>

<p>TODO</p>

<p>Update conda environment:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda <span class="nb">env export</span> <span class="o">&gt;</span> environment.yml
<span class="c"># Tip: backup your env before update</span>
<span class="c"># --prune option removes any packages from the environment that are not listed in the .yml.</span>
conda <span class="nb">env </span>update <span class="nt">--file</span> environment.yml <span class="nt">--prune</span>
</code></pre></div></div>

<h4 id="references">References</h4>
<ul>
    <li><a href="https://sachinjose31.medium.com/creating-an-environment-in-anaconda-through-a-yml-file-7e5deeb7676d">Creating an environment in anaconda through a yml file</a>.</li>
    <li><a href="https://conda.github.io/conda-pack/">Conda pack</a>.</li>
    <li><a href="https://saturncloud.io/blog/updating-an-existing-conda-environment-with-a-yml-file-a-guide/">Updating an Existing Conda Environment with a .yml File: A Guide</a></li>
</ul>]]></content><author><name></name></author><category term="note-posts" /><category term="notes" /><summary type="html"><![CDATA[references]]></summary></entry><entry><title type="html">PyPI your python package</title><link href="http://localhost:4000/blog/2023/PyPI-your-python-package/" rel="alternate" type="text/html" title="PyPI your python package" /><published>2023-07-31T05:00:00-07:00</published><updated>2023-07-31T05:00:00-07:00</updated><id>http://localhost:4000/blog/2023/PyPI-your-python-package</id><content type="html" xml:base="http://localhost:4000/blog/2023/PyPI-your-python-package/"><![CDATA[<h4 id="how-to-install-download-and-build-python-wheels">How to install, download and build Python wheels</h4>

<p>Python Packaging Index (PyPI) is a repository containing several hundred thousand packages.</p>

<h5 id="install-package">Install package</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install a PyPl indexed package optionally with version v.v</span>
pip <span class="nb">install</span> &lt;packagename&gt;[<span class="o">==</span>v.v]

<span class="c"># test install with dry-run</span>
pip <span class="nb">install</span> <span class="nt">--dry-run</span> &lt;packagename&gt;

<span class="c"># Upgrade an installed package</span>
pip <span class="nb">install</span> <span class="nt">--upgrade</span> &lt;packagename&gt;

<span class="c"># Uninstall a package</span>
pip uninstall &lt;packagename&gt;

<span class="c"># Install a package from a repository other than PyPI, such as Github</span>
pip <span class="nb">install</span> <span class="nt">-e</span> git+&lt;https://github.com/myrepo.git#egg<span class="o">=</span>packagename&gt;

<span class="c"># Install a package from specific index url</span>
pip <span class="nb">install</span> &lt;packagename&gt; <span class="nt">--index-url</span> https://some.index.url

<span class="c"># Install a package with extra index url</span>
pip <span class="nb">install</span> &lt;packagename&gt; <span class="nt">--extra-index-url</span> https://some.extra.index.url

<span class="c"># Install package from local .whl file</span>
pip <span class="nb">install</span> /path/to/some/package.whl

pip <span class="nb">install</span> <span class="nt">--find-links</span> /path/to/the/wheel/file/ &lt;package-name&gt;

pip wheel <span class="o">[</span><span class="nt">--no-deps</span><span class="o">]</span> <span class="nt">-w</span> /path/to/the/wheel/files/
</code></pre></div></div>

<h5 id="build-your-own-whl-file">Build your own .whl file</h5>

<h6 id="pure-python-package">Pure python package</h6>

<p>When it comes to Python packaging, if your package consists purely of Python code, you can do the following:</p>

<p><b>1.</b> Make sure Wheel and the latest version of setuptools is installed on your system by running:</p>

<p><code class="language-plaintext highlighter-rouge">python -m pip install -U wheel setuptools</code></p>

<p><b>2.</b> Then run:</p>

<p><code class="language-plaintext highlighter-rouge">python setup.py sdist bdist_wheel</code></p>

<p>This will create both a source distribution (sdist) and a wheel file (bdist_wheel) , along with all of its dependencies. You can now upload your built distributions to PyPI. For more information, see <a href="https://hynek.me/articles/sharing-your-labor-of-love-pypi-quick-and-dirty/">Sharing Your Labor of Love: PyPI Quick and Dirty</a>.</p>

<h6 id="python-package-with-c-libraries">Python package with C libraries</h6>

<p>If your package has linked C libraries, you’ll need to create specific build environments, and then compile your package separately for each target operating system you want to support.</p>

<p>An example of wheel building:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># file structure:</span>
setup.py
src/
    mypkg/
        __init__.py
        module.py
        data/
            tables.dat
            spoons.dat
            forks.dat 
</code></pre></div></div>
<p>Content of <code class="language-plaintext highlighter-rouge">setup.py</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">setuptools</span> <span class="kn">import</span> <span class="n">setup</span>

<span class="nf">setup</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'foo'</span><span class="p">,</span>
      <span class="n">version</span><span class="o">=</span><span class="s">'1.0'</span><span class="p">,</span>
      <span class="n">description</span><span class="o">=</span><span class="s">'Python Distribution Example'</span><span class="p">,</span>
      <span class="n">author</span><span class="o">=</span><span class="s">'lin'</span><span class="p">,</span>
      <span class="n">packages</span><span class="o">=</span><span class="p">[</span><span class="s">'mypkg'</span><span class="p">],</span>
      <span class="n">package_dir</span><span class="o">=</span><span class="p">{</span><span class="s">'mypkg'</span><span class="p">:</span> <span class="s">'src/mypkg'</span><span class="p">},</span>
      <span class="n">package_data</span><span class="o">=</span><span class="p">{</span><span class="s">'mypkg'</span><span class="p">:</span> <span class="p">[</span><span class="s">'data/*.dat'</span><span class="p">]},</span>
      <span class="p">)</span>
</code></pre></div></div>

<p>Another <code class="language-plaintext highlighter-rouge">setup.py</code> for importing prebuilt external lib dependencies through a dummy package:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># file structure:</span>
setup.py
cvcuda_lib/
    libcvcuda.so.0.3.1
    libcvcuda.so.0
    libcvcuda.so
    libnvcv_types.so.0.3.1
    libnvcv_types.so.0
    libnvcv_types.so
    cvcuda.cpython-38-x86_64-linux-gnu.so
    nvcv.cpython-38-x86_64-linux-gnu.so
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">setuptools</span> <span class="kn">import</span> <span class="n">setup</span>

<span class="nf">setup</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s">'cvcuda_import'</span><span class="p">,</span>
    <span class="n">version</span><span class="o">=</span><span class="s">'0.3.1'</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s">'proxy wheel to bring in cvcuda Library'</span><span class="p">,</span>
    <span class="n">data_files</span><span class="o">=</span><span class="p">[(</span><span class="s">'lib'</span><span class="p">,</span> <span class="p">[</span><span class="s">'cvcuda_lib/libcvcuda.so.0.3.1'</span><span class="p">,</span>
                         <span class="s">'cvcuda_lib/libcvcuda.so.0'</span><span class="p">,</span>
                         <span class="s">'cvcuda_lib/libcvcuda.so'</span><span class="p">,</span>
                         <span class="s">'cvcuda_lib/libnvcv_types.so.0.3.1'</span><span class="p">,</span>
                         <span class="s">'cvcuda_lib/libnvcv_types.so.0'</span><span class="p">,</span>
                         <span class="s">'cvcuda_lib/libnvcv_types.so'</span><span class="p">]),</span>
                <span class="p">(</span><span class="s">'lib/python3.8/site-packages'</span><span class="p">,[</span><span class="s">'cvcuda_lib/cvcuda.cpython-38-x86_64-linux-gnu.so'</span><span class="p">,</span>
                                                <span class="s">'cvcuda_lib/nvcv.cpython-38-x86_64-linux-gnu.so'</span><span class="p">])],</span>

    <span class="n">install_requires</span><span class="o">=</span><span class="p">[</span><span class="s">"numpy"</span><span class="p">],</span>
 <span class="p">)</span>
</code></pre></div></div>

<h6 id="upload-your-package-to-pypi">Upload your package to PyPI</h6>

<p><b>1.</b> Wheel naming is automatically generated from the wheel building</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{dist}-{version}(-{build})?-{python.version}-{os_platform}.whl
# deployment with Python 2.7 on 32 bit Windows example:
# PyYAML-5.3.1-cp27-cp27m-win32.whl
</code></pre></div></div>

<p><b>2.</b> Test local installation</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">--find-links</span> /path/to/the/wheel/file/ &lt;package-name&gt;
</code></pre></div></div>

<p><b>3.</b> Upload to the index server</p>

<p>Get the publishing tool <a href="https://pypi.org/project/twine/">twine</a>  for this:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">-U</span> twine
<span class="c"># Since both sdist and bdist_wheel output to dist/ by default, you can safely tell twine to upload everything under dist/ using a shell wildcard (dist/*).</span>
twine upload dist/<span class="k">*</span> <span class="o">[</span><span class="nt">--repository-url</span> https://<span class="nv">$USER</span>:<span class="nv">$API_TOKEN</span>@url.to.the.artifactory]
<span class="c"># if no url is provided, the default index server will be PyPI.</span>
</code></pre></div></div>

<h4 id="references">References</h4>
<ul>
    <li><a href="https://www.activestate.com/resources/quick-reads/python-install-wheel/">How to install, download and build Python wheels</a>.</li>
    <li><a href="https://realpython.com/pypi-publish-python-package/#configuring-your-package">How to Publish an Open-Source Python Package to PyPI</a>.</li>
    <li><a href="https://realpython.com/python-wheels/">What Are Python Wheels and Why Should You Care?</a></li>
    <li><a href="https://docs.python.org/3/distutils/setupscript.html#other-options">Writing the Setup Script</a> with <a href="https://docs.python.org/3/distutils/apiref.html">API</a></li>
    <li><a href="https://packaging.python.org/en/latest/tutorials/packaging-projects/">Packaging Python Projects</a></li>
</ul>]]></content><author><name></name></author><category term="note-posts" /><category term="notes" /><summary type="html"><![CDATA[tutorial]]></summary></entry><entry><title type="html">Triton server tutorial</title><link href="http://localhost:4000/blog/2023/tritonserver/" rel="alternate" type="text/html" title="Triton server tutorial" /><published>2023-07-21T10:49:00-07:00</published><updated>2023-07-21T10:49:00-07:00</updated><id>http://localhost:4000/blog/2023/tritonserver</id><content type="html" xml:base="http://localhost:4000/blog/2023/tritonserver/"><![CDATA[<p><a href="https://www.run.ai/guides/machine-learning-engineering/triton-inference-server">Triton Inference Server: The Basics and a Quick Tutorial</a></p>

<p>Github of <a href="https://github.com/triton-inference-server"> Triton inference server</a>.</p>

<h4 id="introduction">Introduction</h4>

<p>Specify triton model by providing model repository path:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tritonserver <span class="nt">--model-repository</span><span class="o">=</span>&lt;repository-path&gt;
</code></pre></div></div>

<p>There can be multiple versions of each model, with each version stored in a numerically-named subdirectory. The subdirectory’s name must be the model’s version number and it should not be 0.</p>

<p>For example, an ONNX model directory structure looks like this:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;repository-path&gt;/
-&lt;model-name&gt;/
--config.pbtxt
--1/
---model.onnx
</code></pre></div></div>

<p>How Triton Client communicate with Triton?
Through GRPC or HTTP requests, to send inputs to Triton and receive outputs.
Examples could be found <a href="https://github.com/triton-inference-server/server/tree/main/docs/examples/model_repository">here</a>.</p>

<h4 id="install-and-run-triton">Install and Run Triton</h4>

<h5 id="install-triton-docker-image">Install Triton Docker Image</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 
<span class="c">#&lt;xx.yy&gt; represents the version of Triton</span>
</code></pre></div></div>

<h5 id="create-your-model-repository">Create Your Model Repository</h5>

<h5 id="run-triton">Run Triton</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">--gpus</span><span class="o">=</span>3 <span class="nt">--rm</span> <span class="nt">-p8000</span>:8000 <span class="nt">-p8001</span>:8001 <span class="nt">-p8002</span>:8002 <span class="nt">-v</span>/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 tritonserver <span class="nt">--model-repository</span><span class="o">=</span>/models
</code></pre></div></div>]]></content><author><name></name></author><category term="note-posts" /><category term="notes" /><category term="code" /><summary type="html"><![CDATA[Cheatsheet]]></summary></entry><entry><title type="html">What is Docker</title><link href="http://localhost:4000/blog/2023/docker/" rel="alternate" type="text/html" title="What is Docker" /><published>2023-07-21T03:21:00-07:00</published><updated>2023-07-21T03:21:00-07:00</updated><id>http://localhost:4000/blog/2023/docker</id><content type="html" xml:base="http://localhost:4000/blog/2023/docker/"><![CDATA[<h4 id="docker">Docker</h4>
<p><a href="https://djangostars.com/blog/what-is-docker-and-how-to-use-it-with-python/">What is docker and how to use it</a></p>

<h5 id="a-dockerfile-example">A Dockerfile example:</h5>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FROM ubuntu:latest
RUN apt-get update
    <span class="o">&amp;&amp;</span> apt-get <span class="nb">install</span> <span class="nt">--no-install-recommends</span> <span class="nt">--no-install-suggests</span> <span class="nt">-y</span> curl
    <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> /var/lib/apt/lists/<span class="k">*</span>
ENV SITE_URL http://example.com/
WORKDIR /data
VOLUME /data
CMD sh <span class="nt">-c</span> <span class="s2">"curl -Lk </span><span class="nv">$SITE_URL</span><span class="s2"> &gt; /data/results"</span>
</code></pre></div></div>

<h5 id="docker-image-management">Docker image management:</h5>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Build a docker image from a Dockerfile</span>
docker build ./ <span class="nt">-t</span> &lt;image-name&gt;:&lt;version&gt; <span class="o">[</span><span class="nt">-f</span> &lt;path/to/the/Dockerfile&gt;]
<span class="c"># option -t sets the name tag to an image</span>

<span class="c"># check docker image list</span>
docker images

<span class="c"># remove image by image id or image name and tag</span>
docker rmi &lt;image-id&gt;|&lt;image-name&gt;:&lt;image-tag&gt;

</code></pre></div></div>

<h5 id="docker-container-management">Docker container management:</h5>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># run a docker container</span>
docker run <span class="nt">--rm</span> <span class="nt">-e</span> <span class="nv">SITE_URL</span><span class="o">=</span>https://facebook.com/ <span class="o">[</span><span class="nt">-d</span><span class="o">]</span> <span class="o">[</span><span class="nt">-p</span> &lt;HOST-PORT&gt;:&lt;CONTAINER-PORT&gt;] <span class="se">\</span>
<span class="nt">-v</span> <span class="si">$(</span><span class="nb">pwd</span><span class="si">)</span>/vol:/data/:rw &lt;image-name&gt;
<span class="c"># option --rm will remove the container first if it is running</span>
<span class="c"># option -v volume mounting &lt;HOST-DIRECTORY&gt;:&lt;CONTAINER-DIRECTORY&gt;</span>
<span class="c"># option -e sets/overides the env var</span>
<span class="c"># option -d sets the container to run in the background (daemon mode)</span>
<span class="c"># option -p is a ports mapping &lt;HOST-PORT&gt;:&lt;CONTAINER-PORT&gt;</span>

<span class="c"># Check the container's log</span>
docker logs <span class="nt">-f</span> &lt;container-name&gt;

<span class="c"># list the containers</span>
docker ps <span class="o">[</span><span class="nt">-aq</span><span class="o">]</span>
<span class="c"># option -a list all active/running and inactive ones</span>
<span class="c"># option -q to print only container IDs</span>

<span class="c"># start the container</span>
docker start &lt;container-name&gt;

<span class="c"># stop the container</span>
docker stop &lt;container-name&gt;

<span class="c"># remove the container</span>
docker <span class="nb">rm</span> &lt;container-name&gt;

<span class="c"># remove all the containers</span>
docker <span class="nb">rm</span> <span class="nt">-f</span> <span class="si">$(</span>docker ps <span class="nt">-aq</span><span class="si">)</span>
<span class="c"># option -f force to stop and remove the container</span>

<span class="c"># inspect docker container settings</span>
docker inspect &lt;container-name&gt;
</code></pre></div></div>

<h5 id="docker-space-clean-up">Docker space clean up</h5>
<p>Docker saves its data in <code class="language-plaintext highlighter-rouge">/var/lib/docker</code>. The space usage grows quickly.
<a href="https://forums.docker.com/t/some-way-to-clean-up-identify-contents-of-var-lib-docker-overlay/30604/21"> Some ways to identify and clean up the unused content</a>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Enable sudo user to access the protected folder.</span>
<span class="nb">sudo </span>su -

<span class="c"># Check the space usage (Not actual disk usage.)</span>
<span class="c"># -c option to compute the total.</span>
<span class="nb">du</span> <span class="nt">-csh</span> /var/lib/docker/overlay2

<span class="nb">cd</span> /var/lib
<span class="c"># Due to merge folders are mounted using overlay driver, du output is not actual disk allocation size.</span>
<span class="c"># Only check the file sizes in the docker/overlay2/*/diff will give more accurate space usage:</span>
find ./docker/overlay2 <span class="nt">-maxdepth</span> 3 <span class="nt">-type</span> d <span class="nt">-regex</span> <span class="s1">'\.\/docker\/overlay2\/[^ ]*/diff'</span> <span class="nt">-exec</span> <span class="nb">du</span> <span class="nt">-csh</span> <span class="o">{}</span> +
<span class="c"># or</span>
find ./docker/overlay2 <span class="nt">-maxdepth</span> 3 <span class="nt">-type</span> d <span class="nt">-regex</span> <span class="s1">'\.\/docker\/overlay2\/[^ ]*/diff'</span> <span class="nt">-print0</span> | xargs <span class="nt">-r0</span> <span class="nb">sudo du</span> <span class="nt">-csh</span>
<span class="c"># Note this doesn't work: du -ch ./docker/overlay2/*/diff</span>
<span class="c"># du: cannot access './docker/overlay2/*/diff': No such file or directory</span>

<span class="c"># Clean up volume (Not effective on my case)</span>
docker volume <span class="nb">rm</span> <span class="si">$(</span>docker volume <span class="nb">ls</span> <span class="nt">-qf</span> <span class="nv">dangling</span><span class="o">=</span><span class="nb">true</span><span class="si">)</span>

<span class="c"># Prune volumes:</span>
<span class="c"># Caution: this will remove all docker images or containers that are not actively in use.</span>
docker system prune <span class="nt">--all</span> <span class="nt">--volumes</span> <span class="nt">--force</span>

<span class="c"># Check the volumn space</span>
<span class="nb">df</span> <span class="nt">-h</span>
</code></pre></div></div>

<h5 id="additional-execution-on-a-running-docker">Additional execution on a running Docker</h5>
<p>Run <a href="https://docs.docker.com/engine/reference/commandline/exec/">docker exec</a> into a running container:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># First run the container, as an example:</span>
docker run <span class="nt">--name</span> mycontainer <span class="nt">-d</span> <span class="nt">-i</span> <span class="nt">-t</span> alpine /bin/sh
</code></pre></div></div>

<p>This creates and starts a container named mycontainer from an alpine image with an sh shell as its main process. The <code class="language-plaintext highlighter-rouge">-d</code> option (shorthand for <code class="language-plaintext highlighter-rouge">--detach</code>) sets the container to run in the background, in detached mode, with a pseudo-TTY attached (<code class="language-plaintext highlighter-rouge">-t</code>). The <code class="language-plaintext highlighter-rouge">-i</code> option is set to keep STDIN attached, which prevents the sh process from exiting immediately.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Then run sh inside mycontainer</span>
<span class="c"># docker exec [OPTION] CONTAINER COMMAND [ARG...]</span>
docker <span class="nb">exec</span> <span class="nt">-it</span> mycontainer sh
</code></pre></div></div>

<h4 id="deployment">Deployment</h4>

<p><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Kubernetes</a></p>

<p>Data communication between dockers?</p>]]></content><author><name></name></author><category term="note-posts" /><category term="notes" /><summary type="html"><![CDATA[Docker tutorial]]></summary></entry><entry><title type="html">host and remote</title><link href="http://localhost:4000/blog/2023/host-remote/" rel="alternate" type="text/html" title="host and remote" /><published>2023-07-21T00:00:00-07:00</published><updated>2023-07-21T00:00:00-07:00</updated><id>http://localhost:4000/blog/2023/host-remote</id><content type="html" xml:base="http://localhost:4000/blog/2023/host-remote/"><![CDATA[<h2 id="ssh">SSH</h2>
<h3 id="port-forwarding">Port forwarding</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/ssh-port-forwarding-case-1-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/ssh-port-forwarding-case-1-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/ssh-port-forwarding-case-1-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/ssh-port-forwarding-case-1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<div class="caption">
    Fig 1. LocalForward
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/ssh-port-forwarding-case-2-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/ssh-port-forwarding-case-2-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/ssh-port-forwarding-case-2-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/ssh-port-forwarding-case-2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<div class="caption">
    Fig 2. RemoteForward
</div>

<h3 id="trouble-shooting">Trouble shooting</h3>
<p>If the message doesn’t include the authentication method you want to use, take a look at the <code class="language-plaintext highlighter-rouge">/etc/ssh/sshd_config</code> configuration file. There can be a <code class="language-plaintext highlighter-rouge">AuthenticationMethods publickey password</code> to list all allowed methods if not using default setting. In addition, It’s a common error to accidentally set the <code class="language-plaintext highlighter-rouge">PasswordAuthentication</code> value to <code class="language-plaintext highlighter-rouge">yes</code> but <code class="language-plaintext highlighter-rouge">PermitRootLogin</code> to <code class="language-plaintext highlighter-rouge">no</code> or <code class="language-plaintext highlighter-rouge">without-password</code> when logging in as root.</p>

<p>Ensure that the appropriate configuration for your login method is set, then restart the service.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>restart ssh service
</code></pre></div></div>

<p>Another common error for authentication issue is error in Key Permissions And Ownership.</p>

<h2 id="synchronization-tools">Synchronization tools</h2>

<h3 id="scp">scp</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scp <span class="o">[</span>OPTION] <span class="o">[[</span>user@]SRC_HOST:]file1 <span class="o">[[</span>user@]DEST_HOST:]file2
<span class="c"># OPTION:</span>
<span class="c"># -P: Specifies the remote host ssh port.</span>
<span class="c"># -p: Preserves files modification and access times.</span>
<span class="c"># -r: This option tells scp to copy directories recursively.</span>
<span class="c"># -v: verbose.</span>
<span class="c"># -q: suppress the progress meter and non-error messages.</span>
<span class="c"># -C: forces scp to compresses the data as it is sent to the destination machine.</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">scp</code> command relies on <code class="language-plaintext highlighter-rouge">ssh</code> for data transfer, so it requires an <code class="language-plaintext highlighter-rouge">ssh</code>key or password to authenticate on the remote systems.</p>

<p>The colon (<code class="language-plaintext highlighter-rouge">:</code>) is how <code class="language-plaintext highlighter-rouge">scp</code> distinguish between local and remote locations.</p>

<p>Examples:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># From local host to a remote host:</span>
scp <span class="nt">-v</span> <span class="nt">-rp</span> /some/local/path/ &lt;DEVBOX_ID&gt;:/path/at/dest_host

<span class="c"># If SSH on the remote host is listening on a port other than the default 22 </span>
<span class="c"># then you can specify the port using the -P argument:</span>
scp <span class="nt">-P</span> 2322 &lt;file.txt&gt; &lt;remote_username&gt;@10.10.0.2:/remote/directory

<span class="c"># From a remote host to local host</span>
scp <span class="nt">-v</span> <span class="nt">-rp</span> &lt;DEVBOX_ID&gt;:/path/at/dest_host /some/local/path/

<span class="c"># Between two remote hosts</span>
scp user1@host1.com:/files/file.txt user2@host2.com:/files

<span class="c"># To route the traffic through the machine on which the command is issued, </span>
<span class="c"># use the -3 option:</span>
scp <span class="nt">-3</span> user1@host1.com:/files/file.txt user2@host2.com:/files
</code></pre></div></div>

<p>Unlike <code class="language-plaintext highlighter-rouge">rsync</code> , when using <code class="language-plaintext highlighter-rouge">scp</code> you don’t have to log in to one of the servers to transfer files from one to another remote machine.</p>

<h3 id="rsync">rsync</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rsync <span class="o">[</span>OPTION] SRC_HOST DEST_HOST

<span class="c"># pull from remote to local</span>
rsync <span class="o">[</span>OPTION] USER@HOST:SRC DEST

<span class="c"># push from local to remote</span>
rsync <span class="o">[</span>OPTION] SRC USER@HOST:DEST

<span class="c"># OPTION:</span>
<span class="c"># -a: archive mode</span>
<span class="c"># -v: verbose</span>
<span class="c"># -n or --dry-run: execute a test operation without making real changes.</span>
<span class="c"># -u or --update: skip files that are still new in the destination directory</span>
<span class="c"># --ignore-existing: only sync new files.</span>
<span class="c"># --existing: only update existing files, no new files are pulled.</span>
</code></pre></div></div>

<p>Command <code class="language-plaintext highlighter-rouge">rsync</code> need to be used in one of the machines involved in the syncing operation.</p>

<p>One imperative differential of <code class="language-plaintext highlighter-rouge">rsync</code> in comparison to other file-coying commands in Linux is its use of the remote-update protocol, to transfer <em>only the difference</em> between files or directory content. By default, <code class="language-plaintext highlighter-rouge">rsync</code> only copies new or changed files from a source to destination.</p>

<p>Always do a <code class="language-plaintext highlighter-rouge">dry-run</code> before making real changes:
The <code class="language-plaintext highlighter-rouge">--update</code> or <code class="language-plaintext highlighter-rouge">-u</code> option allows <code class="language-plaintext highlighter-rouge">rsync</code> to skip files that are still new in the destination directory, and one important option, <code class="language-plaintext highlighter-rouge">--dry-run</code> or <code class="language-plaintext highlighter-rouge">-n</code> enables us to execute a test operation without making any changes. It shows us what files are to be copied.</p>

<p>Examples:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># push (dry-run)</span>
rsync <span class="nt">-nav</span> <span class="nt">--ignore-existing</span> Documents/<span class="k">*</span> aaronkilik@10.42.1.5:~/all/

<span class="c"># pull (dry-run)</span>
rsync <span class="nt">-nav</span> &lt;DEVBOX_ID&gt;:/path/at/dest_host /some/local/path/ 

<span class="c"># push (dry-run)</span>
rsync <span class="nt">-nav</span> /some/local/path/ &lt;DEVBOX_ID&gt;:/path/at/dest_host
</code></pre></div></div>

<h2 id="reference">Reference</h2>
<p><a href="https://unix.stackexchange.com/questions/115897/whats-ssh-port-forwarding-and-whats-the-difference-between-ssh-local-and-remot">Difference between ssh local and remote port forwarding</a></p>

<p><a href="https://linuxize.com/post/how-to-use-scp-command-to-securely-transfer-files/">How to Use SCP Command to Securely Transfer Files</a></p>

<p><a href="https://www.tecmint.com/sync-new-changed-modified-files-rsync-linux/">How to Use Rsync to Sync New or Changed/Modified Files in Linux</a></p>

<p><a href="https://www.hostinger.com/tutorials/how-to-use-rsync">How to Use the Linux rsync Command for Remote Directory Synchronization</a></p>

<p><a href="https://linuxize.com/post/how-to-setup-passwordless-ssh-login/">SSH key-based authentication</a> and <a href="https://linuxize.com/post/using-the-ssh-config-file/">SSH config file configuration</a></p>

<p><a href="https://docs.digitalocean.com/support/how-to-troubleshoot-ssh-authentication-issues/">How to troubleshoot ssh authentication issues</a></p>

<p><a href="https://rabexc.org/posts/pitfalls-of-ssh-agents">The pitfalls of using ssh-agent, or how to use an agent safely</a></p>

<p><a href="https://github.com/ccontavalli/ssh-ident">ssh-ident:
different agents and different keys for different projects, with ssh.</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[data Synchronization between host and remote machines]]></summary></entry><entry><title type="html">Linux Shell Scripting</title><link href="http://localhost:4000/blog/2023/shell-programming/" rel="alternate" type="text/html" title="Linux Shell Scripting" /><published>2023-06-20T06:43:00-07:00</published><updated>2023-06-20T06:43:00-07:00</updated><id>http://localhost:4000/blog/2023/shell-programming</id><content type="html" xml:base="http://localhost:4000/blog/2023/shell-programming/"><![CDATA[<p><a href="https://bash.cyberciti.biz/guide/Main_Page">Linux Bash Shell Scripting Tutorial</a></p>

<p><a href="https://bash.cyberciti.biz/guide/Set_command">Set command</a></p>]]></content><author><name></name></author><category term="note-posts" /><category term="notes" /><category term="code" /><summary type="html"><![CDATA[Shell programming]]></summary></entry></feed>